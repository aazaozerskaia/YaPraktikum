{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml3SnoUZOrZy"
   },
   "source": [
    "# Классификация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача** - построить модель классификации текстов со значением метрики качества *F1* >= 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ключевые шаги**  \n",
    "1. Обзор данных\n",
    "2. Подготовка текстовой переменной \n",
    "3. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание**  \n",
    "Интернет-магазин запускает новый сервис, где пользователи могут редактировать и дополнять описания товаров. Клиенты смогут предлагать правки и комментировать изменения других. Необходимо разработать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Требуется разработать модель, которая будет определять комментарий позитивный или негативный. Предоставлены размеченные данные с пометкой о токсичности и тексты комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Библиотеки**  \n",
    "pandas, sklearn, nltk, pytorch, catboost, lightgbm, matplotlib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXAw4ud6OrZ5"
   },
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZSmWlZRlOrZ5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cA6RVJMuPDoc",
    "outputId": "27fb6bf7-20f8-469b-f36c-c17a73b25dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 29.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 34.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 32.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0KfhiqFO2S1",
    "outputId": "2f909efb-a14f-48df-c909-e8973d2a0066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7QdXYnjCF60",
    "outputId": "0c7b1d11-37eb-4107-8a35-c87c410b4d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandarallel\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/c9/2350222cec65593ab5f2f00f2e57dfd1fa4e697dbe92fcaff641485354e6/pandarallel-1.5.2.tar.gz\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pandarallel) (0.3.3)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pandarallel: filename=pandarallel-1.5.2-cp37-none-any.whl size=18386 sha256=393de5ceb9ce9f98f7b84fa1265f1ceca4d9e194b0db8c45cba6761f7769b9a0\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/80/6d/d50fb72a8ce6a923fb10390fec9eaaa40b02d07a7ec05c9c05\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: pandarallel\n",
      "Successfully installed pandarallel-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lTdQVW5JOx6c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6az-IOzOrZ8",
    "outputId": "e161b5c2-bae4-42d8-e9db-b8fe806eb574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/80/8e9c57ec32dfed6ba2922bc5c96462cbf8596ce1a6f5de532ad1e43e53fe/catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3MB)\n",
      "\u001b[K     |████████████████████████████████| 67.3MB 62kB/s \n",
      "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKrV6HMBOrZ8",
    "outputId": "b8a5dcc8-2248-4cfc-92b4-e07be3bd60fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7lZUR9R5OrZ8"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AzYUTsz5OrZ9"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FXOVECvyOrZ9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drive/My Drive/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "fp2dk0yIOrZ9",
    "outputId": "b48bacb0-83df-4a2d-9c10-65bf68aa1d54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107690</th>\n",
       "      <td>REDIRECT Talk:Second Time Around (TV series)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29602</th>\n",
       "      <td>\"\\n\\n Manfred I Lancia \\n\\nMy apologies, but I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58513</th>\n",
       "      <td>Really distastefull opinonated personnal attac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27695</th>\n",
       "      <td>I've already restored the separated articles. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104893</th>\n",
       "      <td>It would be inappropriate to split this articl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "107690       REDIRECT Talk:Second Time Around (TV series)      0\n",
       "29602   \"\\n\\n Manfred I Lancia \\n\\nMy apologies, but I...      0\n",
       "58513   Really distastefull opinonated personnal attac...      0\n",
       "27695   I've already restored the separated articles. ...      0\n",
       "104893  It would be inappropriate to split this articl...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyLbe6C3OrZ-",
    "outputId": "b3534df8-0720-491f-bee9-46a012b87195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDMHd8YtOrZ-",
    "outputId": "c52d684d-debc-4382-8756-f9aac49d2d91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.90\n",
       "1   0.10\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3ssAsVnOrZ-"
   },
   "source": [
    "Нам предоставлены данные с описаниями товаров от посетителей сайта и оценкой их токсичности. Всего в датафрейме содержатся 159,6 тыс. описаний. В 90% случаев они отражают отрицательный смысл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZoxu9615C7c"
   },
   "source": [
    "Уберём знакми препинания и лишние символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CKR5szvtVYp1"
   },
   "outputs": [],
   "source": [
    "df['clear_text'] = df['text'].str.replace('[^a-zA-Z]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "E3H_6IiectV-"
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qYHt_03lSxWV"
   },
   "outputs": [],
   "source": [
    "def preclean(text):\n",
    "    token_text = word_tokenize(text.lower())\n",
    "    wo_sw = ' '.join([word for word in token_text if not word in stopwords])\n",
    "    return wo_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbhAP4WITowN",
    "outputId": "25d37b45-d5be-42ef-c439-87b670b6ead3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 489 ms, sys: 297 ms, total: 786 ms\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pandarallel.initialize(verbose=1)\n",
    "df['clear_text'] = df['clear_text'].parallel_apply(preclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "vKZXNDZgTxHB",
    "outputId": "471bbf2f-afed-4adc-b172-39f91ba32d7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118051</th>\n",
       "      <td>Really?  You can't see the blown highlights in...</td>\n",
       "      <td>0</td>\n",
       "      <td>really see blown highlights shirt paleness face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132962</th>\n",
       "      <td>I just wanted to add that there is a differenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>wanted add difference may th movement may th i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137012</th>\n",
       "      <td>You don't add the info to an article, simply t...</td>\n",
       "      <td>0</td>\n",
       "      <td>add info article simply discount go realize di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>The hypocricy of Administrators \\n\\nThere is n...</td>\n",
       "      <td>1</td>\n",
       "      <td>hypocricy administrators community community f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109389</th>\n",
       "      <td>Go to hell \\n\\nFuck you</td>\n",
       "      <td>1</td>\n",
       "      <td>go hell fuck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "118051  Really?  You can't see the blown highlights in...      0   \n",
       "132962  I just wanted to add that there is a differenc...      0   \n",
       "137012  You don't add the info to an article, simply t...      0   \n",
       "13018   The hypocricy of Administrators \\n\\nThere is n...      1   \n",
       "109389                            Go to hell \\n\\nFuck you      1   \n",
       "\n",
       "                                               clear_text  \n",
       "118051    really see blown highlights shirt paleness face  \n",
       "132962  wanted add difference may th movement may th i...  \n",
       "137012  add info article simply discount go realize di...  \n",
       "13018   hypocricy administrators community community f...  \n",
       "109389                                       go hell fuck  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTa9A6w8OraA"
   },
   "source": [
    "### Очищение текста и лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xoHjIABcdoR-"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SsFsSk6QOraA"
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    m = WordNetLemmatizer()\n",
    "    lemm = ' '.join([m.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])\n",
    "    return lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9I3zdE7iXuSE",
    "outputId": "e9464913-4dc9-4d1e-ac2e-8f0919b523c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 723 ms, total: 4.6 s\n",
      "Wall time: 12min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pandarallel.initialize(verbose=1)\n",
    "df['lemm_text'] = df['clear_text'].parallel_apply(lemmatizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "-3_OHuQdURSs",
    "outputId": "4c16b74e-6d40-4e4c-88b9-ebcc69dc412e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109385</th>\n",
       "      <td>And that was why I restored it those times, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>restored times removed tag thumperwad consider...</td>\n",
       "      <td>restore time remove tag thumperwad considers t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147756</th>\n",
       "      <td>September\\n Please stop. If you continue to va...</td>\n",
       "      <td>0</td>\n",
       "      <td>september please stop continue vandalize pages...</td>\n",
       "      <td>september please stop continue vandalize page ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131207</th>\n",
       "      <td>\"\\n\\n Where? \\n\\nI surrender. Non-attorneys ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>surrender non attorneys decided entry genuine ...</td>\n",
       "      <td>surrender non attorney decide entry genuine co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75407</th>\n",
       "      <td>\"\\n  I agree, someone should change this map, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>agree someone change map clearly states soviet...</td>\n",
       "      <td>agree someone change map clearly state soviet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145671</th>\n",
       "      <td>Edit request from Ncmahesh, 14 October 2010 \\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>edit request ncmahesh october baton design cap...</td>\n",
       "      <td>edit request ncmahesh october baton design cap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "109385  And that was why I restored it those times, an...      0   \n",
       "147756  September\\n Please stop. If you continue to va...      0   \n",
       "131207  \"\\n\\n Where? \\n\\nI surrender. Non-attorneys ha...      0   \n",
       "75407   \"\\n  I agree, someone should change this map, ...      0   \n",
       "145671  Edit request from Ncmahesh, 14 October 2010 \\n...      0   \n",
       "\n",
       "                                               clear_text  \\\n",
       "109385  restored times removed tag thumperwad consider...   \n",
       "147756  september please stop continue vandalize pages...   \n",
       "131207  surrender non attorneys decided entry genuine ...   \n",
       "75407   agree someone change map clearly states soviet...   \n",
       "145671  edit request ncmahesh october baton design cap...   \n",
       "\n",
       "                                                lemm_text  \n",
       "109385  restore time remove tag thumperwad considers t...  \n",
       "147756  september please stop continue vandalize page ...  \n",
       "131207  surrender non attorney decide entry genuine co...  \n",
       "75407   agree someone change map clearly state soviet ...  \n",
       "145671  edit request ncmahesh october baton design cap...  "
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxmSv__0OraD"
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9tnpHWE1OraG"
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAK3w8mGOraI"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "l25lyRXSOraI"
   },
   "outputs": [],
   "source": [
    "Y = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OLuEP07OOraI"
   },
   "outputs": [],
   "source": [
    "X = df['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ti2vAZFOOraI"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ru5b8xjcOraJ"
   },
   "outputs": [],
   "source": [
    "def result(prediction):\n",
    "    print('F1: {:.3f}'.format(f1_score(Y_valid, prediction)))\n",
    "    print(classification_report(Y_valid, prediction))\n",
    "    print('AUC: {:.3f}'.format(roc_auc_score(Y_valid, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ggqTFoZdOraJ"
   },
   "outputs": [],
   "source": [
    "train = tf_idf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1fqYpe1EOraJ"
   },
   "outputs": [],
   "source": [
    "valid = tf_idf.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvPWYkryOraK"
   },
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6S1D80A0OraK",
    "outputId": "e0221ed6-88b3-4213-c16d-7d87f42e4dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.47 s, sys: 9.65 s, total: 18.1 s\n",
      "Wall time: 9.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "lr.fit(train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KnaYTlbGOraK"
   },
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBUL4WJYOraL",
    "outputId": "27acd39f-b4d5-448d-9af8-02e88a57f243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     35834\n",
      "           1       0.67      0.86      0.75      4059\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.83      0.90      0.86     39893\n",
      "weighted avg       0.95      0.94      0.95     39893\n",
      "\n",
      "AUC: 0.905\n"
     ]
    }
   ],
   "source": [
    "result(pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DssHq-yjwTI5"
   },
   "outputs": [],
   "source": [
    "lr_sc = f1_score(Y_valid, pred_lr).round(3)\n",
    "lr_auc = roc_auc_score(Y_valid, pred_lr).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov1fJLfaOraL"
   },
   "source": [
    "Логистическая регрессия с учётом балансирования данных, показала целевой F1 = 0.75. Доля правильно предсказанных ответов - 0.94, доля правильно предсказанных среди всех предсказанных = 0.86. Точность предсказания показала, что довольно много объектов отрицательного класса были предсказаны как положительные (ошибки I рода). ROC-AUC = 0.91.  \n",
    "Время обучения и предсказания является преимуществом данной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8ogO3-hOraL"
   },
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NX8JIqLU4V8I"
   },
   "outputs": [],
   "source": [
    "parameters_rf = { 'n_estimators': [20],\n",
    "                  'class_weight': ['balanced'],\n",
    "                  'random_state': [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "xARcLCtAOraL"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "grid_rf = GridSearchCV(rf, parameters_rf, scoring = 'f1', cv=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8XP8QCG5NP8",
    "outputId": "6fdb3d82-ee6d-4b6a-cce0-a2a88e542167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 175 ms, total: 1min 53s\n",
      "Wall time: 3min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced'], 'n_estimators': [20],\n",
       "                         'random_state': [42]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_rf.fit(train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IA88Mj-HOraM",
    "outputId": "04874dd3-03ee-4884-ea7d-4554f2dbe962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     35834\n",
      "           1       0.94      0.46      0.62      4059\n",
      "\n",
      "    accuracy                           0.94     39893\n",
      "   macro avg       0.94      0.73      0.79     39893\n",
      "weighted avg       0.94      0.94      0.93     39893\n",
      "\n",
      "AUC: 0.728\n"
     ]
    }
   ],
   "source": [
    "pred_rf = grid_rf.predict(valid)\n",
    "result(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "m3V_KVw1wUKx"
   },
   "outputs": [],
   "source": [
    "rf_sc = f1_score(Y_valid, pred_rf).round(3)\n",
    "rf_auc = roc_auc_score(Y_valid, pred_rf).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qihsAFpOraM"
   },
   "source": [
    "Модель случайного леса с параметром кол-ва деревьев=20 и сбалансированной выборкой показала F1 = 0.62, что заметно уступает другим моделям. Модель лучше предсказывает нулевой класс и определила меньше половины действительно токсичных комментариев из всех в выборке.\n",
    "Также можно отметить, что модель требует большей оперативности процессора при увеличении числа деревьев, что можно отнести к недостаткам.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyP7m_VpOraM"
   },
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIs34flyOraN",
    "outputId": "2a9a6a4a-b096-4464-bb0c-813985d3854d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's binary_logloss: 0.114964\n",
      "CPU times: user 11min 15s, sys: 905 ms, total: 11min 16s\n",
      "Wall time: 11min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier(n_estimators = 1000, eval_metric = 'F1',  random_state=42)\n",
    "lgbm.fit(train, Y_train, eval_set=(valid, Y_valid), verbose=1000)\n",
    "pred_lgbm = lgbm.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uUeNUbKOraN",
    "outputId": "55ed1e29-b58e-44e1-e28b-6b62157321be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     35834\n",
      "           1       0.88      0.71      0.79      4059\n",
      "\n",
      "    accuracy                           0.96     39893\n",
      "   macro avg       0.92      0.85      0.88     39893\n",
      "weighted avg       0.96      0.96      0.96     39893\n",
      "\n",
      "AUC: 0.851\n"
     ]
    }
   ],
   "source": [
    "result(pred_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "OdG9vR_NvOy6"
   },
   "outputs": [],
   "source": [
    "lgbm_sc = f1_score(Y_valid, pred_lgbm).round(3)\n",
    "lgbm_auc = roc_auc_score(Y_valid, pred_lgbm).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXzs6CgPOraN"
   },
   "source": [
    "На основе сравнения показателей F1 модель lightgbm оказалась лучшей. Полнота предсказания заметно выше, чем у случайного леса, но хуже, чем у логита. Время обучения значительно выше небустинговых моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "kDzetu4gvRsg"
   },
   "outputs": [],
   "source": [
    "train = df[['toxic', 'lemm_text']].sample(frac=0.75, random_state=42).copy()\n",
    "val = df[['toxic', 'lemm_text']][~df.index.isin(train.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "D9511VH5rLWO"
   },
   "outputs": [],
   "source": [
    "XX = ['lemm_text']\n",
    "YY = ['toxic']\n",
    "text = ['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "1LhFoZ6awzl4"
   },
   "outputs": [],
   "source": [
    "params = {'iterations': 200,\n",
    "          'max_depth': 10,\n",
    "          'auto_class_weights': 'Balanced',\n",
    "          'eval_metric': 'F1',\n",
    "          'text_features': text,\n",
    "          'verbose': 100,\n",
    "          'random_state': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "bxBkBQw2xJSt"
   },
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uDZxxl5iEPG",
    "outputId": "448f3e11-95ce-48db-9f04-08ee3c674d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.20808\n",
      "0:\tlearn: 0.8680243\ttest: 0.8806174\tbest: 0.8806174 (0)\ttotal: 3.65s\tremaining: 12m 6s\n",
      "100:\tlearn: 0.9146824\ttest: 0.9038710\tbest: 0.9046358 (93)\ttotal: 5m 58s\tremaining: 5m 51s\n",
      "199:\tlearn: 0.9334451\ttest: 0.9031306\tbest: 0.9049405 (145)\ttotal: 11m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.904940538\n",
      "bestIteration = 145\n",
      "\n",
      "Shrink model to first 146 iterations.\n",
      "CPU times: user 23min 26s, sys: 2.34 s, total: 23min 28s\n",
      "Wall time: 12min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f1a489c2ad0>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cat.fit(train[XX], train[YY], eval_set = (val[XX], val[YY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVF9nT_jiFp7",
    "outputId": "65746849-ccd3-4a23-c0a1-45525c1b0bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.724\n"
     ]
    }
   ],
   "source": [
    "pred_cat = cat.predict(val[XX])\n",
    "print('F1: {:.3f}'.format(f1_score(val[YY], pred_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOxjXZ0bYX5P",
    "outputId": "91066d90-0d11-43ee-d611-4e9bf78f942e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     35772\n",
      "           1       0.62      0.88      0.72      4121\n",
      "\n",
      "    accuracy                           0.93     39893\n",
      "   macro avg       0.80      0.91      0.84     39893\n",
      "weighted avg       0.95      0.93      0.94     39893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val[YY], pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 = 0.72 меньше целевого значения, однако полнота предсказаний 1-го класса модели выше всех и также выше ROC-AUC. Если требуется найти как можно больше токсичных комментариев, то лучше использовать catboost, однако если требуется не перегрузить модерацию ложными токсичными текстами, то это не лучший выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "kjc_l8QivUP7"
   },
   "outputs": [],
   "source": [
    "cat_sc = f1_score(val[YY], pred_cat).round(3)\n",
    "cat_auc = roc_auc_score(val[YY], pred_cat).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns7o_MNtOraO"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "8SyNfvLfOraO"
   },
   "outputs": [],
   "source": [
    "data = {'Logit': [lr_sc, lr_auc],\n",
    "        'RF': [rf_sc, rf_auc],\n",
    "        'LGBM': [lgbm_sc, lgbm_auc],\n",
    "        'CatB': [cat_sc, cat_auc] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LlGmSI1KOraO"
   },
   "outputs": [],
   "source": [
    "f1_scores = pd.DataFrame (data, columns = ['Logit','RF', 'LGBM', 'CatB'], index=['F1', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "_2WQKFGeOraP",
    "outputId": "76bd5343-0d06-4746-9bf6-4e517f5add02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logit</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>CatB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Logit   RF  LGBM  CatB\n",
       "F1    0.75 0.62  0.79  0.72\n",
       "AUC   0.91 0.73  0.85  0.91"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIpODig5OraP"
   },
   "source": [
    "**Вывод**  \n",
    "В условиях задачи лучшей оказалась модель lightgbm с метрикой = 0.79, а хуже всего себя показал случайный лес. Однако если выбирать модель лучшую по времени обучения и с F1 >= 0.75, то лучше выбрать логистическую регрессию, которая также находит больше действительно токсичных комментариев."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "тексты (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
